# lru-cache

A cache object that deletes the least-recently-used items.

Specify a max number of the most recently used items that you
want to keep, and this cache will keep that many of the most
recently accessed items.

This is not primarily a TTL cache, and does not make strong TTL
guarantees. There is no preemptive pruning of expired items by
default, but you _may_ set a TTL on the cache or on a single
`set`. If you do so, it will treat expired items as missing, and
delete them when fetched. If you are more interested in TTL
caching than LRU caching, check out
[@isaacs/ttlcache](http://npm.im/@isaacs/ttlcache).

As of version 7, this is one of the most performant LRU
implementations available in JavaScript, and supports a wide
diversity of use cases. However, note that using some of the
features will necessarily impact performance, by causing the
cache to have to do more work. See the "Performance" section
below.

## Installation

```bash
npm install lru-cache --save
```

## Usage

```js
// hybrid module, either works
import LRUCache from 'lru-cache'
// or:
const LRUCache = require('lru-cache')

// At least one of 'max', 'ttl', or 'maxSize' is required, to prevent
// unsafe unbounded storage.
//
// In most cases, it's best to specify a max for performance, so all
// the required memory allocation is done up-front.
//
// All the other options are optional, see the sections below for
// documentation on what each one does.  Most of them can be
// overridden for specific items in get()/set()
const options = {
  max: 500,

  // for use with tracking overall storage size
  maxSize: 5000,
  sizeCalculation: (value, key) => {
    return 1
  },

  // for use when you need to clean up something when objects
  // are evicted from the cache
  dispose: (value, key) => {
    freeFromMemoryOrWhatever(value)
  },

  // how long to live in ms
  ttl: 1000 * 60 * 5,

  // return stale items before removing from cache?
  allowStale: false,

  updateAgeOnGet: false,
  updateAgeOnHas: false,

  // async method to use for cache.fetch(), for
  // stale-while-revalidate type of behavior
  fetchMethod: async (key, staleValue, { options, signal }) => {},
}

const cache = new LRUCache(options)

cache.set('key', 'value')
cache.get('key') // "value"

// non-string keys ARE fully supported
// but note that it must be THE SAME object, not
// just a JSON-equivalent object.
var someObject = { a: 1 }
cache.set(someObject, 'a value')
// Object keys are not toString()-ed
cache.set('[object Object]', 'a different value')
assert.equal(cache.get(someObject), 'a value')
// A similar object with same keys/values won't work,
// because it's a different object identity
assert.equal(cache.get({ a: 1 }), undefined)

cache.clear() // empty the cache
```

If you put more stuff in it, then items will fall out.

## Options

### `max`

The maximum number of items that remain in the cache (assuming no
TTL pruning or explicit deletions). Note that fewer items may be
stored if size calculation is used, and `maxSize` is exceeded.
This must be a positive finite intger.

At least one of `max`, `maxSize`, or `TTL` is required. This
must be a positive integer if set.

**It is strongly recommended to set a `max` to prevent unbounded
growth of the cache.** See "Storage Bounds Safety" below.

### `maxSize`

Set to a positive integer to track the sizes of items added to
the cache, and automatically evict items in order to stay below
this size. Note that this may result in fewer than `max` items
being stored.

Attempting to add an item to the cache whose calculated size is
greater that this amount will be a no-op. The item will not be
cached, and no other items will be evicted.

Optional, must be a positive integer if provided.

Sets `maxEntrySize` to the same value, unless a different value
is provided for `maxEntrySize`.

At least one of `max`, `maxSize`, or `TTL` is required. This
must be a positive integer if set.

Even if size tracking is enabled, **it is strongly recommended to
set a `max` to prevent unbounded growth of the cache.** See
"Storage Bounds Safety" below.

### `maxEntrySize`

Set to a positive integer to track the sizes of items added to
the cache, and prevent caching any item over a given size.
Attempting to add an item whose calculated size is greater than
this amount will be a no-op. The item will not be cached, and no
other items will be evicted.

Optional, must be a positive integer if provided. Defaults to
the value of `maxSize` if provided.

### `sizeCalculation`

Function used to calculate the size of stored items. If you're
storing strings or buffers, then you probably want to do
something like `n => n.length`. The item is passed as the first
argument, and the key is passed as the second argument.

This may be overridden by passing an options object to
`cache.set()`.

Requires `maxSize` to be set.

If the `size` (or return value of `sizeCalculation`) for a given
entry is greater than `maxEntrySize`, then the item will not be
added to the cache.

Deprecated alias: `length`

### `fetchMethod`

Function that is used to make background asynchronous fetches.
Called with `fetchMethod(key, staleValue, { signal, options,
context })`. May return a Promise.

If `fetchMethod` is not provided, then `cache.fetch(key)` is
equivalent to `Promise.resolve(cache.get(key))`.

The `signal` object is an `AbortSignal` if that's available in
the global object, otherwise it's a pretty close polyfill.

If at any time, `signal.aborted` is set to `true`, or if the
`signal.onabort` method is called, or if it emits an `'abort'`
event which you can listen to with `addEventListener`, then that
means that the fetch should be abandoned. This may be passed
along to async functions aware of AbortController/AbortSignal
behavior.

The `fetchMethod` should **only** return `undefined` or a Promise
resolving to `undefined` if the AbortController signaled an
`abort` event. In all other cases, it should return or resolve
to a value suitable for adding to the cache.

The `options` object is a union of the options that may be
provided to `set()` and `get()`. If they are modified, then that
will result in modifying the settings to `cache.set()` when the
value is resolved, and in the case of `noDeleteOnFetchRejection`
and `allowStaleOnFetchRejection`, the handling of `fetchMethod`
failures.

For example, a DNS cache may update the TTL based on the value
returned from a remote DNS server by changing `options.ttl` in
the `fetchMethod`.

### `fetchContext`

Arbitrary data that can be passed to the `fetchMethod` as the
`context` option.

Note that this will only be relevant when the `cache.fetch()`
call needs to call `fetchMethod()`. Thus, any data which will
meaningfully vary the fetch response needs to be present in the
key. This is primarily intended for including `x-request-id`
headers and the like for debugging purposes, which do not affect
the `fetchMethod()` response.

### `noDeleteOnFetchRejection`

If a `fetchMethod` throws an error or returns a rejected promise,
then by default, any existing stale value will be removed from
the cache.

If `noDeleteOnFetchRejection` is set to `true`, then this
behavior is suppressed, and the stale value remains in the cache
in the case of a rejected `fetchMethod`.

This is important in cases where a `fetchMethod` is _only_ called
as a background update while the stale value is returned, when
`allowStale` is used.

This is implicitly in effect when `allowStaleOnFetchRejection` is
set.

This may be set in calls to `fetch()`, or defaulted on the
constructor, or overridden by modifying the options object in the
`fetchMethod`.

### `allowStaleOnFetchRejection`

Set to true to return a stale value from the cache when a
`fetchMethod` throws an error or returns a rejected Promise.

If a `fetchMethod` fails, and there is no stale value available,
the `fetch()` will resolve to `undefined`. Ie, all `fetchMethod`
errors are suppressed.

Implies `noDeleteOnFetchRejection`.

This may be set in calls to `fetch()`, or defaulted on the
constructor, or overridden by modifying the options object in the
`fetchMethod`.

### `allowStaleOnFetchAbort`

Set to true to return a stale value from the cache when the
`AbortSignal` passed to the `fetchMethod` dispatches an `'abort'`
event, whether user-triggered, or due to internal cache behavior.

Unless `ignoreFetchAbort` is also set, the underlying
`fetchMethod` will still be considered canceled, and its return
value will be ignored and not cached.

### `ignoreFetchAbort`

Set to true to ignore the `abort` event emitted by the
`AbortSignal` object passed to `fetchMethod`, and still cache the
resulting resolution value, as long as it is not `undefined`.

When used on its own, this means aborted `fetch()` calls are not
immediately resolved or rejected when they are aborted, and
instead take the full time to await.

When used with `allowStaleOnFetchAbort`, aborted `fetch()` calls
will resolve immediately to their stale cached value or
`undefined`, and will continue to process and eventually update
the cache when they resolve, as long as the resulting value is
not `undefined`, thus supporting a "return stale on timeout while
refreshing" mechanism by passing `A